{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ja-ginza nltk svgling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi1-_Gs4gM8Z",
        "outputId": "0c4a4b21-9fcc-43bb-9b6c-46fed92c85b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ja-ginza\n",
            "  Downloading ja_ginza-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting svgling\n",
            "  Downloading svgling-0.5.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.4.4 in /usr/local/lib/python3.11/dist-packages (from ja-ginza) (3.8.7)\n",
            "Collecting sudachipy<0.7.0,>=0.6.2 (from ja-ginza)\n",
            "  Downloading SudachiPy-0.6.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting sudachidict-core>=20210802 (from ja-ginza)\n",
            "  Downloading sudachidict_core-20250515-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting ginza<5.3.0,>=5.2.0 (from ja-ginza)\n",
            "  Downloading ginza-5.2.0-py3-none-any.whl.metadata (448 bytes)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Collecting svgwrite (from svgling)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting plac>=1.3.3 (from ginza<5.3.0,>=5.2.0->ja-ginza)\n",
            "  Downloading plac-1.4.5-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ja-ginza) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja-ginza) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja-ginza) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja-ginza) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja-ginza) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja-ginza) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja-ginza) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja-ginza) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja-ginza) (2025.6.15)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.4.4->ja-ginza) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.4.4->ja-ginza) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja-ginza) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja-ginza) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ja-ginza) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ja-ginza) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<4.0.0,>=3.4.4->ja-ginza) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ja-ginza) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja-ginza) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja-ginza) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ja-ginza) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja-ginza) (0.1.2)\n",
            "Downloading ja_ginza-5.2.0-py3-none-any.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading svgling-0.5.0-py3-none-any.whl (31 kB)\n",
            "Downloading ginza-5.2.0-py3-none-any.whl (21 kB)\n",
            "Downloading sudachidict_core-20250515-py3-none-any.whl (72.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SudachiPy-0.6.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plac-1.4.5-py2.py3-none-any.whl (22 kB)\n",
            "Installing collected packages: sudachipy, plac, svgwrite, sudachidict-core, svgling, ginza, ja-ginza\n",
            "Successfully installed ginza-5.2.0 ja-ginza-5.2.0 plac-1.4.5 sudachidict-core-20250515 sudachipy-0.6.10 svgling-0.5.0 svgwrite-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ginza spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r1akI2FChik",
        "outputId": "5967b952-15d3-4b48-a8fa-bb241e8f4e55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ginza in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: plac>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from ginza) (1.4.5)\n",
            "Requirement already satisfied: SudachiPy<0.7.0,>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from ginza) (0.6.10)\n",
            "Requirement already satisfied: SudachiDict-core>=20210802 in /usr/local/lib/python3.11/dist-packages (from ginza) (20250515)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"https://github.com/megagonlabs/ginza/releases/download/latest/ginza-latest.tar.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbORFA9rCs3R",
        "outputId": "b0c0330f-034c-4568-ec37-5c7d8a124b90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/megagonlabs/ginza/releases/download/latest/ginza-latest.tar.gz\n",
            "  Downloading https://github.com/megagonlabs/ginza/releases/download/latest/ginza-latest.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.4.4 in /usr/local/lib/python3.11/dist-packages (from ginza==5.2.0) (3.8.7)\n",
            "Requirement already satisfied: plac>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from ginza==5.2.0) (1.4.5)\n",
            "Requirement already satisfied: SudachiPy<0.7.0,>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from ginza==5.2.0) (0.6.10)\n",
            "Requirement already satisfied: SudachiDict-core>=20210802 in /usr/local/lib/python3.11/dist-packages (from ginza==5.2.0) (20250515)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=3.4.4->ginza==5.2.0) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (2025.6.15)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza==5.2.0) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk\n",
        "from nltk import CFG, ChartParser\n",
        "from nltk.tree import Tree\n",
        "from spacy.lang.ja import Japanese\n",
        "\n",
        "nlp = Japanese()"
      ],
      "metadata": {
        "id": "seb4Ez9egWMS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryJapaneseParser:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initializes parser with binary Japanese grammar\"\"\"\n",
        "        self.grammar = CFG.fromstring(\"\"\"\n",
        "            S -> S1 | S2 | S3 | S4 | S5 | S6 | S7\n",
        "\n",
        "            NP_TOPIC -> NP \"は\" | NP \"も\" | NP\n",
        "\n",
        "            S1 -> NP_TOPIC VP\n",
        "            S1 -> NP VP\n",
        "            S2 -> S1 \"か\"\n",
        "            S3 -> NP_TOPIC VP_NEG\n",
        "            S4 -> V_IMP | VP_IMP_NEG\n",
        "            S5 -> COND VP\n",
        "            S6 -> NP_PASSIVE V_PASSIVE\n",
        "            S7 -> NP REL_NOUN\n",
        "\n",
        "            NP -> DET NOUN\n",
        "            NP -> NOUN\n",
        "            NP -> PRONOUN\n",
        "            NP -> NP_PARTICLE\n",
        "            NP -> NP_NOUN\n",
        "\n",
        "            NP_PARTICLE -> NP PARTICLE\n",
        "            NP_NOUN -> NP \"の\" NOUN\n",
        "            NP_PASSIVE -> NP \"に\"\n",
        "            REL_NOUN -> VP \"の\" NOUN\n",
        "\n",
        "            VP -> V\n",
        "            VP -> V_AUX\n",
        "            VP -> V_NP\n",
        "            VP -> ADJ\n",
        "            VP -> ADJ_DESU\n",
        "            VP -> ADV_VP\n",
        "            VP -> VP_PP\n",
        "            V -> V_STEM V_INFL | V_WHOLE\n",
        "\n",
        "            V_AUX -> V AUX\n",
        "            V_NP -> NP V\n",
        "            VP_NEG -> VP \"ない\"\n",
        "            VP_NEG -> ADJ \"ない\"\n",
        "            ADV_VP -> ADV VP\n",
        "            VP_PP -> VP PP\n",
        "            VP_IMP_NEG -> V_STEM \"なさい\"\n",
        "\n",
        "            V_WHOLE -> \"食べる\" | \"読む\" | \"いる\" | \"ある\" | \"走る\" | \"降る\" | \"褒める\" | \"走れ\" | \"見る\" | \"する\"\n",
        "            V_STEM -> \"食べ\" | \"読み\" | \"い\" | \"あ\" | \"走り\" | \"降り\" | \"褒め\" | \"見\"\n",
        "            V_INFL -> \"る\" | \"た\" | \"て\" | \"れば\" | \"ろ\" | \"ます\" | \"ません\"\n",
        "\n",
        "            V_IMP -> V_IMP_BASE | V_IMP_SUFFIX\n",
        "            V_IMP_BASE -> \"走れ\" | \"降れ\" | \"見ろ\"\n",
        "            V_IMP_SUFFIX -> V_STEM \"ろ\" | V_TE \"ください\"\n",
        "            V_TE -> V_STEM \"て\"\n",
        "            V_PASSIVE -> V_STEM \"られる\"\n",
        "\n",
        "            ADJ_DESU -> ADJ \"です\"\n",
        "\n",
        "            COND -> NP PARTICLE V_COND \"ば\"\n",
        "            V_COND -> V_STEM \"れ\"\n",
        "\n",
        "            PP -> NP POSTPOSITION\n",
        "\n",
        "            AUX -> \"ます\" | \"ました\" | \"たい\" | \"られる\" | \"ない\"\n",
        "            ADJ -> \"大きい\" | \"小さい\" | \"美味しい\" | \"速い\" | \"可愛い\" | \"新しい\" | \"高い\"\n",
        "            ADV -> \"とても\" | \"速く\" | \"よく\" | \"もっと\"\n",
        "            POSTPOSITION -> \"で\" | \"に\" | \"から\" | \"まで\" | \"へ\" | \"と\"\n",
        "\n",
        "            DET -> \"その\" | \"この\" | \"あの\" | \"どの\"\n",
        "            NOUN -> \"本\" | \"猫\" | \"学生\" | \"先生\" | \"公園\" | \"魚\" | \"家\" | \"雨\" | \"犬\" | \"声\" | \"車\" | \"学校\" | \"エドゥアルドクリシンスキ\"\n",
        "            PRONOUN -> \"私\" | \"あなた\" | \"彼\" | \"彼女\" | \"誰\"\n",
        "            PARTICLE -> \"が\" | \"を\" | \"に\" | \"で\" | \"へ\" | \"と\" | \"から\"\n",
        "        \"\"\")\n",
        "        self.parser = ChartParser(self.grammar)\n",
        "\n",
        "    def parse_sentence(self, sentence):\n",
        "        doc = nlp(sentence)\n",
        "        tokens = []\n",
        "        for token in doc:\n",
        "          tokens.append(str(token))\n",
        "        try:\n",
        "            trees = list(self.parser.parse(tokens))\n",
        "            # print([t for t in trees if isinstance(t, Tree)]) #\n",
        "            return [t for t in trees if isinstance(t, Tree)]\n",
        "        except (ValueError, IndexError) as e:\n",
        "            print(f\"Parsing error: {e}\")\n",
        "            return []\n",
        "\n",
        "    def analyze_sentence(self, sentence):\n",
        "        print(f\"\\nAnalyzing: 「{sentence}」\")\n",
        "        trees = self.parse_sentence(sentence)\n",
        "        # print('print(trees)')\n",
        "        # print(trees) #\n",
        "\n",
        "        if not trees:\n",
        "            print(\"> Sentence doesn't match grammar\")\n",
        "            return False\n",
        "\n",
        "        print(f\"> Found {len(trees)} parse tree{'s' if len(trees) > 1 else ''}:\")\n",
        "        for i, tree in enumerate(trees, 1):\n",
        "            print(f\"\\nTree {i}:\")\n",
        "            tree.pretty_print()\n",
        "            self._analyze_tree(tree)\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _analyze_tree(self, tree):\n",
        "        def get_sentence_type(tree):\n",
        "            labels = {\n",
        "                'S1': 'Declarative',\n",
        "                'S2': 'Question',\n",
        "                'S3': 'Negative',\n",
        "                'S4': 'Imperative',\n",
        "                'S5': 'Conditional',\n",
        "                'S6': 'Passive',\n",
        "                'S7': 'Relative'\n",
        "            }\n",
        "            first_child = tree[0]  # Gets the first subtree\n",
        "            first_child_label = first_child.label()\n",
        "            return labels.get(str(first_child_label))\n",
        "\n",
        "        print(f\"\\nSentence type: {get_sentence_type(tree)}\")\n",
        "\n",
        "        def analyze_node(node, depth=0):\n",
        "            indent = \"  \" * depth\n",
        "            if isinstance(node, str):\n",
        "                print(f\"{indent}Token: {node}\")\n",
        "            else:\n",
        "                print(f\"{indent}{node.label()}:\")\n",
        "                for child in node:\n",
        "                  analyze_node(child, depth+1)\n",
        "\n",
        "        return analyze_node(tree)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = BinaryJapaneseParser()\n",
        "\n",
        "    # Test sentences\n",
        "    test_sentences = [\n",
        "        \"猫は魚を食べる\",\n",
        "        \"本を読む\",\n",
        "        \"読みなさい\",\n",
        "        \"雨が降る\",\n",
        "        \"先生に褒められる\",\n",
        "        \"私は走る\",\n",
        "        \"この本を読みます\",\n",
        "        \"公園で走る\",\n",
        "        \"彼女は家にいる\"\n",
        "    ]\n",
        "\n",
        "    print(\"=== Testing Basic Sentences ===\")\n",
        "    for sentence in test_sentences:\n",
        "        parser.analyze_sentence(sentence)\n",
        "\n",
        "    # More complex sentences\n",
        "    print(\"\\n=== Testing Complex Sentences ===\")\n",
        "    complex_sentences = [\n",
        "        \"本を読むの学生\",\n",
        "        \"雨が降れば家にいる\",\n",
        "        \"私はとても速く走る\"\n",
        "    ]\n",
        "    for sentence in complex_sentences:\n",
        "        parser.analyze_sentence(sentence)\n",
        "\n",
        "    # Interactive mode\n",
        "    print(\"\\n=== Interactive Mode ===\")\n",
        "    print(\"Enter Japanese sentence, or 'q' to quit\")\n",
        "    while True:\n",
        "        user_input = input(\"> \").strip()\n",
        "        if user_input.lower() == 'q':\n",
        "            break\n",
        "        if user_input:\n",
        "            parser.analyze_sentence(user_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1f2QiWtYA6fB",
        "outputId": "53d7d140-05ec-4a1d-a4a1-1af2fc830e0b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Testing Basic Sentences ===\n",
            "\n",
            "Analyzing: 「猫は魚を食べる」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S1', [Tree('NP_TOPIC', [Tree('NP', [Tree('NOUN', ['猫'])]), 'は']), Tree('VP', [Tree('V_NP', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('NOUN', ['魚'])]), Tree('PARTICLE', ['を'])])]), Tree('V', [Tree('V_WHOLE', ['食べる'])])])])])])]\n",
            "> Found 1 parse tree:\n",
            "\n",
            "Tree 1:\n",
            "                   S                               \n",
            "                   |                                \n",
            "                   S1                              \n",
            "        ___________|__________________              \n",
            "       |                              VP           \n",
            "       |                              |             \n",
            "       |                             V_NP          \n",
            "       |                     _________|________     \n",
            "       |                    NP                 |   \n",
            "       |                    |                  |    \n",
            "    NP_TOPIC           NP_PARTICLE             |   \n",
            "  _____|______      ________|_________         |    \n",
            " |            NP   NP                 |        V   \n",
            " |            |    |                  |        |    \n",
            " |           NOUN NOUN             PARTICLE V_WHOLE\n",
            " |            |    |                  |        |    \n",
            " は            猫    魚                  を       食べる  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP_TOPIC:\n",
            "      NP:\n",
            "        NOUN:\n",
            "          Token: 猫\n",
            "      Token: は\n",
            "    VP:\n",
            "      V_NP:\n",
            "        NP:\n",
            "          NP_PARTICLE:\n",
            "            NP:\n",
            "              NOUN:\n",
            "                Token: 魚\n",
            "            PARTICLE:\n",
            "              Token: を\n",
            "        V:\n",
            "          V_WHOLE:\n",
            "            Token: 食べる\n",
            "\n",
            "Analyzing: 「本を読む」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S1', [Tree('NP_TOPIC', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('NOUN', ['本'])]), Tree('PARTICLE', ['を'])])])]), Tree('VP', [Tree('V', [Tree('V_WHOLE', ['読む'])])])])]), Tree('S', [Tree('S1', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('NOUN', ['本'])]), Tree('PARTICLE', ['を'])])]), Tree('VP', [Tree('V', [Tree('V_WHOLE', ['読む'])])])])])]\n",
            "> Found 2 parse trees:\n",
            "\n",
            "Tree 1:\n",
            "                    S            \n",
            "                    |             \n",
            "                    S1           \n",
            "           _________|________     \n",
            "       NP_TOPIC              |   \n",
            "          |                  |    \n",
            "          NP                 |   \n",
            "          |                  |    \n",
            "     NP_PARTICLE             VP  \n",
            "  ________|_________         |    \n",
            " NP                 |        V   \n",
            " |                  |        |    \n",
            "NOUN             PARTICLE V_WHOLE\n",
            " |                  |        |    \n",
            " 本                  を        読む  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP_TOPIC:\n",
            "      NP:\n",
            "        NP_PARTICLE:\n",
            "          NP:\n",
            "            NOUN:\n",
            "              Token: 本\n",
            "          PARTICLE:\n",
            "            Token: を\n",
            "    VP:\n",
            "      V:\n",
            "        V_WHOLE:\n",
            "          Token: 読む\n",
            "\n",
            "Tree 2:\n",
            "                    S            \n",
            "                    |             \n",
            "                    S1           \n",
            "           _________|________     \n",
            "          NP                 |   \n",
            "          |                  |    \n",
            "     NP_PARTICLE             VP  \n",
            "  ________|_________         |    \n",
            " NP                 |        V   \n",
            " |                  |        |    \n",
            "NOUN             PARTICLE V_WHOLE\n",
            " |                  |        |    \n",
            " 本                  を        読む  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP:\n",
            "      NP_PARTICLE:\n",
            "        NP:\n",
            "          NOUN:\n",
            "            Token: 本\n",
            "        PARTICLE:\n",
            "          Token: を\n",
            "    VP:\n",
            "      V:\n",
            "        V_WHOLE:\n",
            "          Token: 読む\n",
            "\n",
            "Analyzing: 「読みなさい」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S4', [Tree('VP_IMP_NEG', [Tree('V_STEM', ['読み']), 'なさい'])])])]\n",
            "> Found 1 parse tree:\n",
            "\n",
            "Tree 1:\n",
            "        S            \n",
            "        |             \n",
            "        S4           \n",
            "        |             \n",
            "    VP_IMP_NEG       \n",
            "  ______|________     \n",
            " |             V_STEM\n",
            " |               |    \n",
            "なさい              読み  \n",
            "\n",
            "\n",
            "Sentence type: Imperative\n",
            "S:\n",
            "  S4:\n",
            "    VP_IMP_NEG:\n",
            "      V_STEM:\n",
            "        Token: 読み\n",
            "      Token: なさい\n",
            "\n",
            "Analyzing: 「雨が降る」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S1', [Tree('NP_TOPIC', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('NOUN', ['雨'])]), Tree('PARTICLE', ['が'])])])]), Tree('VP', [Tree('V', [Tree('V_WHOLE', ['降る'])])])])]), Tree('S', [Tree('S1', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('NOUN', ['雨'])]), Tree('PARTICLE', ['が'])])]), Tree('VP', [Tree('V', [Tree('V_WHOLE', ['降る'])])])])])]\n",
            "> Found 2 parse trees:\n",
            "\n",
            "Tree 1:\n",
            "                    S            \n",
            "                    |             \n",
            "                    S1           \n",
            "           _________|________     \n",
            "       NP_TOPIC              |   \n",
            "          |                  |    \n",
            "          NP                 |   \n",
            "          |                  |    \n",
            "     NP_PARTICLE             VP  \n",
            "  ________|_________         |    \n",
            " NP                 |        V   \n",
            " |                  |        |    \n",
            "NOUN             PARTICLE V_WHOLE\n",
            " |                  |        |    \n",
            " 雨                  が        降る  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP_TOPIC:\n",
            "      NP:\n",
            "        NP_PARTICLE:\n",
            "          NP:\n",
            "            NOUN:\n",
            "              Token: 雨\n",
            "          PARTICLE:\n",
            "            Token: が\n",
            "    VP:\n",
            "      V:\n",
            "        V_WHOLE:\n",
            "          Token: 降る\n",
            "\n",
            "Tree 2:\n",
            "                    S            \n",
            "                    |             \n",
            "                    S1           \n",
            "           _________|________     \n",
            "          NP                 |   \n",
            "          |                  |    \n",
            "     NP_PARTICLE             VP  \n",
            "  ________|_________         |    \n",
            " NP                 |        V   \n",
            " |                  |        |    \n",
            "NOUN             PARTICLE V_WHOLE\n",
            " |                  |        |    \n",
            " 雨                  が        降る  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP:\n",
            "      NP_PARTICLE:\n",
            "        NP:\n",
            "          NOUN:\n",
            "            Token: 雨\n",
            "        PARTICLE:\n",
            "          Token: が\n",
            "    VP:\n",
            "      V:\n",
            "        V_WHOLE:\n",
            "          Token: 降る\n",
            "\n",
            "Analyzing: 「先生に褒められる」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S6', [Tree('NP_PASSIVE', [Tree('NP', [Tree('NOUN', ['先生'])]), 'に']), Tree('V_PASSIVE', [Tree('V_STEM', ['褒め']), 'られる'])])])]\n",
            "> Found 1 parse tree:\n",
            "\n",
            "Tree 1:\n",
            "                     S                      \n",
            "                     |                       \n",
            "                     S6                     \n",
            "         ____________|__________             \n",
            "    NP_PASSIVE                  |           \n",
            "  ______|_______                |            \n",
            " |              NP          V_PASSIVE       \n",
            " |              |         ______|_______     \n",
            " |             NOUN      |            V_STEM\n",
            " |              |        |              |    \n",
            " に              先生      られる             褒め  \n",
            "\n",
            "\n",
            "Sentence type: Passive\n",
            "S:\n",
            "  S6:\n",
            "    NP_PASSIVE:\n",
            "      NP:\n",
            "        NOUN:\n",
            "          Token: 先生\n",
            "      Token: に\n",
            "    V_PASSIVE:\n",
            "      V_STEM:\n",
            "        Token: 褒め\n",
            "      Token: られる\n",
            "\n",
            "Analyzing: 「私は走る」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S1', [Tree('NP_TOPIC', [Tree('NP', [Tree('PRONOUN', ['私'])]), 'は']), Tree('VP', [Tree('V', [Tree('V_WHOLE', ['走る'])])])])])]\n",
            "> Found 1 parse tree:\n",
            "\n",
            "Tree 1:\n",
            "                S           \n",
            "                |            \n",
            "                S1          \n",
            "        ________|_______     \n",
            "    NP_TOPIC            VP  \n",
            "  _____|________        |    \n",
            " |              NP      V   \n",
            " |              |       |    \n",
            " |           PRONOUN V_WHOLE\n",
            " |              |       |    \n",
            " は              私       走る  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP_TOPIC:\n",
            "      NP:\n",
            "        PRONOUN:\n",
            "          Token: 私\n",
            "      Token: は\n",
            "    VP:\n",
            "      V:\n",
            "        V_WHOLE:\n",
            "          Token: 走る\n",
            "\n",
            "Analyzing: 「この本を読みます」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S1', [Tree('NP_TOPIC', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('DET', ['この']), Tree('NOUN', ['本'])]), Tree('PARTICLE', ['を'])])])]), Tree('VP', [Tree('V', [Tree('V_STEM', ['読み']), Tree('V_INFL', ['ます'])])])])]), Tree('S', [Tree('S1', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('DET', ['この']), Tree('NOUN', ['本'])]), Tree('PARTICLE', ['を'])])]), Tree('VP', [Tree('V', [Tree('V_STEM', ['読み']), Tree('V_INFL', ['ます'])])])])])]\n",
            "> Found 2 parse trees:\n",
            "\n",
            "Tree 1:\n",
            "                       S                      \n",
            "                       |                       \n",
            "                       S1                     \n",
            "              _________|_____________          \n",
            "          NP_TOPIC                   |        \n",
            "             |                       |         \n",
            "             NP                      |        \n",
            "             |                       |         \n",
            "        NP_PARTICLE                  VP       \n",
            "      _______|_________              |         \n",
            "     NP                |             V        \n",
            "  ___|_______          |        _____|____     \n",
            "DET         NOUN    PARTICLE V_STEM     V_INFL\n",
            " |           |         |       |          |    \n",
            " この          本         を       読み         ます  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP_TOPIC:\n",
            "      NP:\n",
            "        NP_PARTICLE:\n",
            "          NP:\n",
            "            DET:\n",
            "              Token: この\n",
            "            NOUN:\n",
            "              Token: 本\n",
            "          PARTICLE:\n",
            "            Token: を\n",
            "    VP:\n",
            "      V:\n",
            "        V_STEM:\n",
            "          Token: 読み\n",
            "        V_INFL:\n",
            "          Token: ます\n",
            "\n",
            "Tree 2:\n",
            "                       S                      \n",
            "                       |                       \n",
            "                       S1                     \n",
            "              _________|_____________          \n",
            "             NP                      |        \n",
            "             |                       |         \n",
            "        NP_PARTICLE                  VP       \n",
            "      _______|_________              |         \n",
            "     NP                |             V        \n",
            "  ___|_______          |        _____|____     \n",
            "DET         NOUN    PARTICLE V_STEM     V_INFL\n",
            " |           |         |       |          |    \n",
            " この          本         を       読み         ます  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP:\n",
            "      NP_PARTICLE:\n",
            "        NP:\n",
            "          DET:\n",
            "            Token: この\n",
            "          NOUN:\n",
            "            Token: 本\n",
            "        PARTICLE:\n",
            "          Token: を\n",
            "    VP:\n",
            "      V:\n",
            "        V_STEM:\n",
            "          Token: 読み\n",
            "        V_INFL:\n",
            "          Token: ます\n",
            "\n",
            "Analyzing: 「公園で走る」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S1', [Tree('NP_TOPIC', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('NOUN', ['公園'])]), Tree('PARTICLE', ['で'])])])]), Tree('VP', [Tree('V', [Tree('V_WHOLE', ['走る'])])])])]), Tree('S', [Tree('S1', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('NOUN', ['公園'])]), Tree('PARTICLE', ['で'])])]), Tree('VP', [Tree('V', [Tree('V_WHOLE', ['走る'])])])])])]\n",
            "> Found 2 parse trees:\n",
            "\n",
            "Tree 1:\n",
            "                    S            \n",
            "                    |             \n",
            "                    S1           \n",
            "           _________|________     \n",
            "       NP_TOPIC              |   \n",
            "          |                  |    \n",
            "          NP                 |   \n",
            "          |                  |    \n",
            "     NP_PARTICLE             VP  \n",
            "  ________|_________         |    \n",
            " NP                 |        V   \n",
            " |                  |        |    \n",
            "NOUN             PARTICLE V_WHOLE\n",
            " |                  |        |    \n",
            " 公園                 で        走る  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP_TOPIC:\n",
            "      NP:\n",
            "        NP_PARTICLE:\n",
            "          NP:\n",
            "            NOUN:\n",
            "              Token: 公園\n",
            "          PARTICLE:\n",
            "            Token: で\n",
            "    VP:\n",
            "      V:\n",
            "        V_WHOLE:\n",
            "          Token: 走る\n",
            "\n",
            "Tree 2:\n",
            "                    S            \n",
            "                    |             \n",
            "                    S1           \n",
            "           _________|________     \n",
            "          NP                 |   \n",
            "          |                  |    \n",
            "     NP_PARTICLE             VP  \n",
            "  ________|_________         |    \n",
            " NP                 |        V   \n",
            " |                  |        |    \n",
            "NOUN             PARTICLE V_WHOLE\n",
            " |                  |        |    \n",
            " 公園                 で        走る  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP:\n",
            "      NP_PARTICLE:\n",
            "        NP:\n",
            "          NOUN:\n",
            "            Token: 公園\n",
            "        PARTICLE:\n",
            "          Token: で\n",
            "    VP:\n",
            "      V:\n",
            "        V_WHOLE:\n",
            "          Token: 走る\n",
            "\n",
            "Analyzing: 「彼女は家にいる」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S1', [Tree('NP_TOPIC', [Tree('NP', [Tree('PRONOUN', ['彼女'])]), 'は']), Tree('VP', [Tree('V_NP', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('NOUN', ['家'])]), Tree('PARTICLE', ['に'])])]), Tree('V', [Tree('V_WHOLE', ['いる'])])])])])])]\n",
            "> Found 1 parse tree:\n",
            "\n",
            "Tree 1:\n",
            "                      S                               \n",
            "                      |                                \n",
            "                      S1                              \n",
            "        ______________|__________________              \n",
            "       |                                 VP           \n",
            "       |                                 |             \n",
            "       |                                V_NP          \n",
            "       |                        _________|________     \n",
            "       |                       NP                 |   \n",
            "       |                       |                  |    \n",
            "    NP_TOPIC              NP_PARTICLE             |   \n",
            "  _____|________       ________|_________         |    \n",
            " |              NP    NP                 |        V   \n",
            " |              |     |                  |        |    \n",
            " |           PRONOUN NOUN             PARTICLE V_WHOLE\n",
            " |              |     |                  |        |    \n",
            " は              彼女    家                  に        いる  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP_TOPIC:\n",
            "      NP:\n",
            "        PRONOUN:\n",
            "          Token: 彼女\n",
            "      Token: は\n",
            "    VP:\n",
            "      V_NP:\n",
            "        NP:\n",
            "          NP_PARTICLE:\n",
            "            NP:\n",
            "              NOUN:\n",
            "                Token: 家\n",
            "            PARTICLE:\n",
            "              Token: に\n",
            "        V:\n",
            "          V_WHOLE:\n",
            "            Token: いる\n",
            "\n",
            "=== Testing Complex Sentences ===\n",
            "\n",
            "Analyzing: 「本を読むの学生」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S7', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('NOUN', ['本'])]), Tree('PARTICLE', ['を'])])]), Tree('REL_NOUN', [Tree('VP', [Tree('V', [Tree('V_WHOLE', ['読む'])])]), 'の', Tree('NOUN', ['学生'])])])])]\n",
            "> Found 1 parse tree:\n",
            "\n",
            "Tree 1:\n",
            "                           S               \n",
            "                           |                \n",
            "                           S7              \n",
            "           ________________|_____           \n",
            "          NP                  REL_NOUN     \n",
            "          |                 _____|______    \n",
            "     NP_PARTICLE           |     VP     |  \n",
            "  ________|_________       |     |      |   \n",
            " NP                 |      |     V      |  \n",
            " |                  |      |     |      |   \n",
            "NOUN             PARTICLE  |  V_WHOLE  NOUN\n",
            " |                  |      |     |      |   \n",
            " 本                  を      の     読む     学生 \n",
            "\n",
            "\n",
            "Sentence type: Relative\n",
            "S:\n",
            "  S7:\n",
            "    NP:\n",
            "      NP_PARTICLE:\n",
            "        NP:\n",
            "          NOUN:\n",
            "            Token: 本\n",
            "        PARTICLE:\n",
            "          Token: を\n",
            "    REL_NOUN:\n",
            "      VP:\n",
            "        V:\n",
            "          V_WHOLE:\n",
            "            Token: 読む\n",
            "      Token: の\n",
            "      NOUN:\n",
            "        Token: 学生\n",
            "\n",
            "Analyzing: 「雨が降れば家にいる」\n",
            "print(trees)\n",
            "[]\n",
            "> Sentence doesn't match grammar\n",
            "\n",
            "Analyzing: 「私はとても速く走る」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S1', [Tree('NP_TOPIC', [Tree('NP', [Tree('PRONOUN', ['私'])]), 'は']), Tree('VP', [Tree('ADV_VP', [Tree('ADV', ['とても']), Tree('VP', [Tree('ADV_VP', [Tree('ADV', ['速く']), Tree('VP', [Tree('V', [Tree('V_WHOLE', ['走る'])])])])])])])])])]\n",
            "> Found 1 parse tree:\n",
            "\n",
            "Tree 1:\n",
            "                      S                       \n",
            "                      |                        \n",
            "                      S1                      \n",
            "        ______________|____                    \n",
            "       |                   VP                 \n",
            "       |                   |                   \n",
            "       |                 ADV_VP               \n",
            "       |               ____|______             \n",
            "       |              |           VP          \n",
            "       |              |           |            \n",
            "       |              |         ADV_VP        \n",
            "       |              |     ______|_______     \n",
            "    NP_TOPIC          |    |              VP  \n",
            "  _____|________      |    |              |    \n",
            " |              NP    |    |              V   \n",
            " |              |     |    |              |    \n",
            " |           PRONOUN ADV  ADV          V_WHOLE\n",
            " |              |     |    |              |    \n",
            " は              私    とても   速く             走る  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP_TOPIC:\n",
            "      NP:\n",
            "        PRONOUN:\n",
            "          Token: 私\n",
            "      Token: は\n",
            "    VP:\n",
            "      ADV_VP:\n",
            "        ADV:\n",
            "          Token: とても\n",
            "        VP:\n",
            "          ADV_VP:\n",
            "            ADV:\n",
            "              Token: 速く\n",
            "            VP:\n",
            "              V:\n",
            "                V_WHOLE:\n",
            "                  Token: 走る\n",
            "\n",
            "=== Interactive Mode ===\n",
            "Enter Japanese sentence, or 'q' to quit\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-56-457419256.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter Japanese sentence, or 'q' to quit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = BinaryJapaneseParser()\n",
        "parser.analyze_sentence(\"猫は本を見る\") # кошка видит книгу"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc0x3EjUC0-i",
        "outputId": "9b43d704-fb6f-4d5d-ebad-1cafede03491"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analyzing: 「猫は本を見る」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S1', [Tree('NP_TOPIC', [Tree('NP', [Tree('NOUN', ['猫'])]), 'は']), Tree('VP', [Tree('V_NP', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('NOUN', ['本'])]), Tree('PARTICLE', ['を'])])]), Tree('V', [Tree('V_WHOLE', ['見る'])])])])])])]\n",
            "> Found 1 parse tree:\n",
            "\n",
            "Tree 1:\n",
            "                   S                               \n",
            "                   |                                \n",
            "                   S1                              \n",
            "        ___________|__________________              \n",
            "       |                              VP           \n",
            "       |                              |             \n",
            "       |                             V_NP          \n",
            "       |                     _________|________     \n",
            "       |                    NP                 |   \n",
            "       |                    |                  |    \n",
            "    NP_TOPIC           NP_PARTICLE             |   \n",
            "  _____|______      ________|_________         |    \n",
            " |            NP   NP                 |        V   \n",
            " |            |    |                  |        |    \n",
            " |           NOUN NOUN             PARTICLE V_WHOLE\n",
            " |            |    |                  |        |    \n",
            " は            猫    本                  を        見る  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP_TOPIC:\n",
            "      NP:\n",
            "        NOUN:\n",
            "          Token: 猫\n",
            "      Token: は\n",
            "    VP:\n",
            "      V_NP:\n",
            "        NP:\n",
            "          NP_PARTICLE:\n",
            "            NP:\n",
            "              NOUN:\n",
            "                Token: 本\n",
            "            PARTICLE:\n",
            "              Token: を\n",
            "        V:\n",
            "          V_WHOLE:\n",
            "            Token: 見る\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = BinaryJapaneseParser()\n",
        "parser.analyze_sentence(\"エドゥアルドクリシンスキは学生を見ます\") # Эдуард Клышинский посмотрит на студентов"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjdFZdlZ6Fty",
        "outputId": "5b0dc52c-6716-41bf-8133-f0e098ca0376"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analyzing: 「エドゥアルドクリシンスキは学生を見ます」\n",
            "print(trees)\n",
            "[Tree('S', [Tree('S1', [Tree('NP_TOPIC', [Tree('NP', [Tree('NOUN', ['エドゥアルドクリシンスキ'])]), 'は']), Tree('VP', [Tree('V_NP', [Tree('NP', [Tree('NP_PARTICLE', [Tree('NP', [Tree('NOUN', ['学生'])]), Tree('PARTICLE', ['を'])])]), Tree('V', [Tree('V_STEM', ['見']), Tree('V_INFL', ['ます'])])])])])])]\n",
            "> Found 1 parse tree:\n",
            "\n",
            "Tree 1:\n",
            "                           S                                              \n",
            "                           |                                               \n",
            "                           S1                                             \n",
            "        ___________________|_________________________                      \n",
            "       |                                             VP                   \n",
            "       |                                             |                     \n",
            "       |                                            V_NP                  \n",
            "       |                             ________________|___________          \n",
            "       |                            NP                           |        \n",
            "       |                            |                            |         \n",
            "    NP_TOPIC                   NP_PARTICLE                       |        \n",
            "  _____|__________          ________|_________                   |         \n",
            " |                NP       NP                 |                  V        \n",
            " |                |        |                  |             _____|____     \n",
            " |               NOUN     NOUN             PARTICLE      V_STEM     V_INFL\n",
            " |                |        |                  |            |          |    \n",
            " は           エドゥアルドクリシンスキ  学生                 を            見          ます  \n",
            "\n",
            "\n",
            "Sentence type: Declarative\n",
            "S:\n",
            "  S1:\n",
            "    NP_TOPIC:\n",
            "      NP:\n",
            "        NOUN:\n",
            "          Token: エドゥアルドクリシンスキ\n",
            "      Token: は\n",
            "    VP:\n",
            "      V_NP:\n",
            "        NP:\n",
            "          NP_PARTICLE:\n",
            "            NP:\n",
            "              NOUN:\n",
            "                Token: 学生\n",
            "            PARTICLE:\n",
            "              Token: を\n",
            "        V:\n",
            "          V_STEM:\n",
            "            Token: 見\n",
            "          V_INFL:\n",
            "            Token: ます\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fTCDHMZk6OiL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}